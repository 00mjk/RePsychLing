{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RePsychLing Kleigl et al. (2011)\n",
    "\n",
    "This is a set of follow-up analyses to Kliegl et al. (2011).\n",
    "\n",
    "Reinhold Kliegl, Ping Wei, Michael Dambacher, Ming Yan, & Xiaolin Zhou (2011). Experimental Effects and Individual Differences in Linear Mixed Models: Estimating the Relation between Spatial, Object, and Attraction Effects in Visual Attention. Frontiers in Psychology, 1, 1-12.\n",
    "\n",
    "We are using the final set of data used in paper, that is after filtering a few outlier responses, defining `sdif` contrasts for factor `tar` and corresponding vector-valued contrasts `spt`, `c2`, `c3` from model matrix. The dataframe also includes transformations of the `rt` (`lrt=log(rt)`, `srt=sqrt(rt)`, `rrt=1000/rt` (note change in effect direction), `prt=rt^0.4242424` (acc to boxcox); `subj = factor(id)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><tr><th></th><th>item</th><th>tar</th><th>dir</th><th>rt</th><th>subj</th><th>c1</th><th>c2</th><th>c3</th><th>srt</th><th>lrt</th><th>qrt</th><th>prt</th></tr><tr><th>1</th><td>39</td><td>dod</td><td>hor</td><td>506.1</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.5061</td><td>6.226734278220032</td><td>22.4966664197165</td><td>14.036235047977032</td></tr><tr><th>2</th><td>52</td><td>dod</td><td>hor</td><td>489.6</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.48960000000000004</td><td>6.193588731198116</td><td>22.126906697502932</td><td>13.840242483234347</td></tr><tr><th>3</th><td>89</td><td>dod</td><td>hor</td><td>518.7</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.5187</td><td>6.251325681357355</td><td>22.774986278810356</td><td>14.183437487026127</td></tr><tr><th>4</th><td>104</td><td>dod</td><td>hor</td><td>459.6</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.4596</td><td>6.130356545974601</td><td>21.438283513378586</td><td>13.473903246772165</td></tr><tr><th>5</th><td>120</td><td>dod</td><td>hor</td><td>384.2</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.3842</td><td>5.9511632503344565</td><td>19.601020381602584</td><td>12.487565630398025</td></tr><tr><th>6</th><td>161</td><td>dod</td><td>hor</td><td>470.0</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.47</td><td>6.152732694704104</td><td>21.6794833886788</td><td>13.6024187183506</td></tr><tr><th>7</th><td>194</td><td>dod</td><td>hor</td><td>422.0</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.422</td><td>6.045005314036012</td><td>20.54263858417414</td><td>12.994746292564496</td></tr><tr><th>8</th><td>248</td><td>dod</td><td>hor</td><td>462.8</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.4628</td><td>6.137294995319522</td><td>21.51278689523977</td><td>13.513623211612503</td></tr><tr><th>9</th><td>270</td><td>dod</td><td>hor</td><td>471.9</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.4719</td><td>6.156767098732342</td><td>21.723259423944647</td><td>13.625720058735002</td></tr><tr><th>10</th><td>277</td><td>dod</td><td>hor</td><td>445.5</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.4455</td><td>6.099197246910864</td><td>21.106870919205434</td><td>13.29696266938164</td></tr><tr><th>11</th><td>289</td><td>dod</td><td>hor</td><td>399.1</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.3991</td><td>5.989212012054688</td><td>19.977487329491666</td><td>12.690774122389815</td></tr><tr><th>12</th><td>299</td><td>dod</td><td>hor</td><td>389.7</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.3897</td><td>5.965377212344664</td><td>19.74082065163452</td><td>12.563095143693552</td></tr><tr><th>13</th><td>304</td><td>dod</td><td>hor</td><td>409.8</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.4098</td><td>6.0156692358048</td><td>20.243517480912253</td><td>12.834021158252208</td></tr><tr><th>14</th><td>320</td><td>dod</td><td>hor</td><td>370.1</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.37010000000000004</td><td>5.9137732393921105</td><td>19.237983262286097</td><td>12.291045469327695</td></tr><tr><th>15</th><td>378</td><td>dod</td><td>hor</td><td>408.2</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.4082</td><td>6.011757250375744</td><td>20.203960007879644</td><td>12.812739115708265</td></tr><tr><th>16</th><td>479</td><td>dod</td><td>hor</td><td>417.5</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.4175</td><td>6.0342845442909105</td><td>20.43281674170255</td><td>12.935777779076782</td></tr><tr><th>17</th><td>494</td><td>dod</td><td>hor</td><td>316.7</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.3167</td><td>5.757954953544594</td><td>17.79606698121807</td><td>11.50482284638836</td></tr><tr><th>18</th><td>503</td><td>dod</td><td>hor</td><td>440.7</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.4407</td><td>6.088364371847941</td><td>20.992855927672156</td><td>13.235993220286256</td></tr><tr><th>19</th><td>508</td><td>dod</td><td>hor</td><td>398.7</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.3987</td><td>5.988209254387309</td><td>19.967473550752484</td><td>12.685376464020894</td></tr><tr><th>20</th><td>554</td><td>dod</td><td>hor</td><td>348.7</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.3487</td><td>5.854211953681605</td><td>18.673510650116114</td><td>11.984361453423922</td></tr><tr><th>21</th><td>587</td><td>dod</td><td>hor</td><td>275.0</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.275</td><td>5.616771097666572</td><td>16.583123951777</td><td>10.835959687916407</td></tr><tr><th>22</th><td>590</td><td>dod</td><td>hor</td><td>411.2</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.4112</td><td>6.019079714140955</td><td>20.27806696901852</td><td>12.852603734733455</td></tr><tr><th>23</th><td>4</td><td>dod</td><td>ver</td><td>525.7</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.5257000000000001</td><td>6.264730707825403</td><td>22.928148638736623</td><td>14.264328138370793</td></tr><tr><th>24</th><td>40</td><td>dod</td><td>ver</td><td>466.7</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.4667</td><td>6.14568665295577</td><td>21.603240497666086</td><td>13.561818714724618</td></tr><tr><th>25</th><td>79</td><td>dod</td><td>ver</td><td>469.4</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.4694</td><td>6.151455283416923</td><td>21.66564100136435</td><td>13.595049135993305</td></tr><tr><th>26</th><td>116</td><td>dod</td><td>ver</td><td>484.2</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.48419999999999996</td><td>6.182498044503958</td><td>22.004544985070698</td><td>13.77527523217376</td></tr><tr><th>27</th><td>164</td><td>dod</td><td>ver</td><td>518.2</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.5182</td><td>6.250361268128009</td><td>22.764006677208652</td><td>14.177635597194842</td></tr><tr><th>28</th><td>167</td><td>dod</td><td>ver</td><td>519.8</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.5197999999999999</td><td>6.25344412220739</td><td>22.799122790142604</td><td>14.19619032008118</td></tr><tr><th>29</th><td>169</td><td>dod</td><td>ver</td><td>505.8</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.5058</td><td>6.226141334235865</td><td>22.489997776789576</td><td>14.032704652660527</td></tr><tr><th>30</th><td>177</td><td>dod</td><td>ver</td><td>465.0</td><td>1</td><td>0.25</td><td>0.5</td><td>-0.75</td><td>0.465</td><td>6.142037405587356</td><td>21.563858652847824</td><td>13.540839039367318</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></table>"
      ],
      "text/plain": [
       "28710x12 DataFrame\n",
       "| Row   | item  | tar   | dir   | rt    | subj | c1    | c2   | c3    | srt    |\n",
       "|-------|-------|-------|-------|-------|------|-------|------|-------|--------|\n",
       "| 1     | \"39\"  | \"dod\" | \"hor\" | 506.1 | \"1\"  | 0.25  | 0.5  | -0.75 | 0.5061 |\n",
       "| 2     | \"52\"  | \"dod\" | \"hor\" | 489.6 | \"1\"  | 0.25  | 0.5  | -0.75 | 0.4896 |\n",
       "| 3     | \"89\"  | \"dod\" | \"hor\" | 518.7 | \"1\"  | 0.25  | 0.5  | -0.75 | 0.5187 |\n",
       "| 4     | \"104\" | \"dod\" | \"hor\" | 459.6 | \"1\"  | 0.25  | 0.5  | -0.75 | 0.4596 |\n",
       "| 5     | \"120\" | \"dod\" | \"hor\" | 384.2 | \"1\"  | 0.25  | 0.5  | -0.75 | 0.3842 |\n",
       "| 6     | \"161\" | \"dod\" | \"hor\" | 470.0 | \"1\"  | 0.25  | 0.5  | -0.75 | 0.47   |\n",
       "| 7     | \"194\" | \"dod\" | \"hor\" | 422.0 | \"1\"  | 0.25  | 0.5  | -0.75 | 0.422  |\n",
       "| 8     | \"248\" | \"dod\" | \"hor\" | 462.8 | \"1\"  | 0.25  | 0.5  | -0.75 | 0.4628 |\n",
       "| 9     | \"270\" | \"dod\" | \"hor\" | 471.9 | \"1\"  | 0.25  | 0.5  | -0.75 | 0.4719 |\n",
       "| 10    | \"277\" | \"dod\" | \"hor\" | 445.5 | \"1\"  | 0.25  | 0.5  | -0.75 | 0.4455 |\n",
       "| 11    | \"289\" | \"dod\" | \"hor\" | 399.1 | \"1\"  | 0.25  | 0.5  | -0.75 | 0.3991 |\n",
       "â‹®\n",
       "| 28699 | \"566\" | \"val\" | \"ver\" | 349.4 | \"61\" | -0.75 | -0.5 | 0.25  | 0.3494 |\n",
       "| 28700 | \"577\" | \"val\" | \"ver\" | 577.8 | \"61\" | -0.75 | -0.5 | 0.25  | 0.5778 |\n",
       "| 28701 | \"578\" | \"val\" | \"ver\" | 334.7 | \"61\" | -0.75 | -0.5 | 0.25  | 0.3347 |\n",
       "| 28702 | \"580\" | \"val\" | \"ver\" | 346.2 | \"61\" | -0.75 | -0.5 | 0.25  | 0.3462 |\n",
       "| 28703 | \"581\" | \"val\" | \"ver\" | 302.3 | \"61\" | -0.75 | -0.5 | 0.25  | 0.3023 |\n",
       "| 28704 | \"586\" | \"val\" | \"ver\" | 328.3 | \"61\" | -0.75 | -0.5 | 0.25  | 0.3283 |\n",
       "| 28705 | \"591\" | \"val\" | \"ver\" | 353.7 | \"61\" | -0.75 | -0.5 | 0.25  | 0.3537 |\n",
       "| 28706 | \"592\" | \"val\" | \"ver\" | 376.0 | \"61\" | -0.75 | -0.5 | 0.25  | 0.376  |\n",
       "| 28707 | \"593\" | \"val\" | \"ver\" | 295.9 | \"61\" | -0.75 | -0.5 | 0.25  | 0.2959 |\n",
       "| 28708 | \"596\" | \"val\" | \"ver\" | 254.3 | \"61\" | -0.75 | -0.5 | 0.25  | 0.2543 |\n",
       "| 28709 | \"600\" | \"val\" | \"ver\" | 282.6 | \"61\" | -0.75 | -0.5 | 0.25  | 0.2826 |\n",
       "| 28710 | \"602\" | \"val\" | \"ver\" | 450.5 | \"61\" | -0.75 | -0.5 | 0.25  | 0.4505 |\n",
       "\n",
       "| Row   | lrt     | qrt     | prt     |\n",
       "|-------|---------|---------|---------|\n",
       "| 1     | 6.22673 | 22.4967 | 14.0362 |\n",
       "| 2     | 6.19359 | 22.1269 | 13.8402 |\n",
       "| 3     | 6.25133 | 22.775  | 14.1834 |\n",
       "| 4     | 6.13036 | 21.4383 | 13.4739 |\n",
       "| 5     | 5.95116 | 19.601  | 12.4876 |\n",
       "| 6     | 6.15273 | 21.6795 | 13.6024 |\n",
       "| 7     | 6.04501 | 20.5426 | 12.9947 |\n",
       "| 8     | 6.13729 | 21.5128 | 13.5136 |\n",
       "| 9     | 6.15677 | 21.7233 | 13.6257 |\n",
       "| 10    | 6.0992  | 21.1069 | 13.297  |\n",
       "| 11    | 5.98921 | 19.9775 | 12.6908 |\n",
       "â‹®\n",
       "| 28699 | 5.85622 | 18.6922 | 11.9946 |\n",
       "| 28700 | 6.35923 | 24.0375 | 14.8478 |\n",
       "| 28701 | 5.81323 | 18.2948 | 11.7778 |\n",
       "| 28702 | 5.84702 | 18.6065 | 11.9478 |\n",
       "| 28703 | 5.71142 | 17.3868 | 11.2799 |\n",
       "| 28704 | 5.79393 | 18.1191 | 11.6817 |\n",
       "| 28705 | 5.86845 | 18.8069 | 12.057  |\n",
       "| 28706 | 5.92959 | 19.3907 | 12.3738 |\n",
       "| 28707 | 5.69002 | 17.2017 | 11.178  |\n",
       "| 28708 | 5.53851 | 15.9468 | 10.4821 |\n",
       "| 28709 | 5.64403 | 16.8107 | 10.962  |\n",
       "| 28710 | 6.11036 | 21.225  | 13.3601 |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames,RCall,MixedModels\n",
    "kwdyz = DataFrame(\"RePsychLing::KWDYZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "### Maximal linear mixed model (_maxLMM_) \n",
    "\n",
    "The maximal model (_maxLMM_) reported in this paper is actually an overparameterized/degenerate model. Here we show how to identify the overparameterization and how we tried to deal with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       "Formula: rt ~ 1 + c1 + c2 + c3 + ((1 + c1 + c2 + c3) | subj)\n",
       "\n",
       " logLik: -162904.774673, deviance: 325809.549347\n",
       "\n",
       " Variance components:\n",
       "                Variance    Std.Dev.  Corr.\n",
       " subj         3047.168904   55.201168\n",
       "              540.507922   23.248826   0.60\n",
       "              115.651117   10.754121  -0.13 -0.13\n",
       "               90.443092    9.510157  -0.25 -0.25 -0.25\n",
       " Residual     4876.903925   69.834833\n",
       " Number of obs: 28710; levels of grouping factors: 61\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error z value\n",
       "(Intercept)   389.734   7.09149 54.9579\n",
       "c1            33.7817   3.28744  10.276\n",
       "c2            13.9852   2.30574 6.06539\n",
       "c3            2.74695   2.21425 1.24058\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0 = fit(lmm(rt ~ 1+c1+c2+c3 + (1+c1+c2+c3|subj), kwdyz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " PDLCholF(Cholesky{Float64} with factor:\n",
       "4x4 Triangular{Float64,Array{Float64,2},:L,false}:\n",
       "  0.790453    0.0        0.0       0.0\n",
       "  0.201073    0.26533    0.0       0.0\n",
       " -0.0202282   0.0137804  0.152036  0.0\n",
       " -0.0338984  -0.119124   0.056618  0.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0.Î»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " [0.820001,0.282049,0.161098,0.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(svdvals,m0.Î»)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The singular value decomposition (svd) and the form of the $\\lambda$ matrix itself show that the estimated covariance matrix from the unconditional distribution of the random effects is singular.\n",
    "\n",
    "### Zero-correlation parameter linear mixed model (zcppLMM)\n",
    "\n",
    "One option to reduce the complexity of the _maxLMM_ is to force correlation parameters to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       "Formula: rt ~ 1 + c1 + c2 + c3 + (1 | subj) + ((0 + c1) | subj) + ((0 + c2) | subj) + ((0 + c3) | subj)\n",
       "\n",
       " logLik: -162933.484994, deviance: 325866.969987\n",
       "\n",
       " Variance components:\n",
       "                Variance    Std.Dev.  Corr.\n",
       " subj         3000.448567   54.776350\n",
       "              696.365808   26.388744   0.00\n",
       "                0.000000    0.000000   0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00\n",
       " Residual     4888.337817   69.916649\n",
       " Number of obs: 28710; levels of grouping factors: 61\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error z value\n",
       "(Intercept)   389.732   7.03734 55.3806\n",
       "c1            33.7618   3.65606 9.23446\n",
       "c2            14.0247   1.85135 7.57537\n",
       "c3            2.77449   1.85134 1.49864\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = fit(lmm(rt ~ 1+c1+c2+c3 + \n",
    "(1|subj)+(0+c1|subj)+(0+c2|subj)+(0+c3|subj), kwdyz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better fit is obtained by `lmer` at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325848.60722980055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MixedModels.objective!(m1,[0.783409125819598, 0.343236594542506, \n",
    "    0.148817522465133, 0.123267732858873])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       "Formula: rt ~ 1 + c1 + c2 + c3 + (1 | subj) + ((0 + c1) | subj) + ((0 + c2) | subj) + ((0 + c3) | subj)\n",
       "\n",
       " logLik: -162924.303615, deviance: 325848.607230\n",
       "\n",
       " Variance components:\n",
       "                Variance    Std.Dev.  Corr.\n",
       " subj         2993.405273   54.712021\n",
       "              574.613927   23.971106   0.00\n",
       "              108.017873   10.393165   0.00  0.00\n",
       "               74.111792    8.608821   0.00  0.00  0.00\n",
       " Residual     4877.415190   69.838494\n",
       " Number of obs: 28710; levels of grouping factors: 61\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error z value\n",
       "(Intercept)   389.728   7.02908  55.445\n",
       "c1             33.774    3.3715 10.0175\n",
       "c2            14.0033   2.27855 6.14568\n",
       "c3            2.78726   2.15314 1.29451\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.fit = false; fit(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><tr><th></th><th>Df</th><th>Deviance</th><th>Chisq</th><th>pval</th></tr><tr><th>1</th><td>9</td><td>325848.6072297999</td><td>NaN</td><td>NaN</td></tr><tr><th>2</th><td>15</td><td>325809.5493466815</td><td>39.057883118395694</td><td>6.973019046337306e-7</td></tr></table>"
      ],
      "text/plain": [
       "2x4 DataFrame\n",
       "| Row | Df | Deviance | Chisq   | pval       |\n",
       "|-----|----|----------|---------|------------|\n",
       "| 1   | 9  | 325849.0 | NaN     | NaN        |\n",
       "| 2   | 15 | 325810.0 | 39.0579 | 6.97302e-7 |"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MixedModels.lrt(m1,m0) # significant, too much reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no exact singularity for the _zcpLMM_. This model, however, fits significantly worse than _maxLMM_. Thus, removing all correlation parameters was too much of a reduction in model complexity. Before checking invidual correlation parameters for inclusion, we check whether any of the variance components are not supported b the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       "Formula: rt ~ 1 + c1 + c2 + c3 + ((1 + c1 + c2) | subj)\n",
       "\n",
       " logLik: -162913.894074, deviance: 325827.788149\n",
       "\n",
       " Variance components:\n",
       "                Variance    Std.Dev.  Corr.\n",
       " subj         3046.867891   55.198441\n",
       "              536.876928   23.170605   0.61\n",
       "               96.794222    9.838405  -0.02 -0.02\n",
       " Residual     4881.760085   69.869593\n",
       " Number of obs: 28710; levels of grouping factors: 61\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error z value\n",
       "(Intercept)   389.734   7.09117 54.9604\n",
       "c1            33.7795   3.27867 10.3028\n",
       "c2            14.0089   2.23836 6.25853\n",
       "c3            2.78883   1.85014 1.50736\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = fit(lmm(rt ~ 1+c1+c2+c3 + (1+c1+c2|subj),kwdyz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><tr><th></th><th>Df</th><th>Deviance</th><th>Chisq</th><th>pval</th></tr><tr><th>1</th><td>11</td><td>325827.7881488834</td><td>NaN</td><td>NaN</td></tr><tr><th>2</th><td>15</td><td>325809.5493466815</td><td>18.238802201871295</td><td>0.0011082793310690378</td></tr></table>"
      ],
      "text/plain": [
       "2x4 DataFrame\n",
       "| Row | Df | Deviance | Chisq   | pval       |\n",
       "|-----|----|----------|---------|------------|\n",
       "| 1   | 11 | 325828.0 | NaN     | NaN        |\n",
       "| 2   | 15 | 325810.0 | 18.2388 | 0.00110828 |"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MixedModels.lrt(m2,m0)  # still highly significant change from m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " PDLCholF(Cholesky{Float64} with factor:\n",
       "3x3 Triangular{Float64,Array{Float64,2},:L,false}:\n",
       "  0.790021    0.0       0.0     \n",
       "  0.200855    0.263882  0.0     \n",
       " -0.00308719  0.076954  0.117882)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.Î»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using lrt=log(rt) or prt= rt^power (acc Box-Cox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       "Formula: lrt ~ 1 + c1 + c2 + c3 + ((1 + c1 + c2 + c3) | subj)\n",
       "\n",
       " logLik: 6391.186870, deviance: -12782.373741\n",
       "\n",
       " Variance components:\n",
       "                Variance    Std.Dev.  Corr.\n",
       " subj           0.020765    0.144100\n",
       "                0.003385    0.058178   0.48\n",
       "                0.000753    0.027442  -0.24 -0.24\n",
       "                0.000622    0.024941  -0.30 -0.30 -0.30\n",
       " Residual       0.036854    0.191975\n",
       " Number of obs: 28710; levels of grouping factors: 61\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "              Estimate  Std.Error z value\n",
       "(Intercept)    5.93583  0.0185187 320.532\n",
       "c1           0.0877736 0.00837831 10.4763\n",
       "c2           0.0366027 0.00618003 5.92273\n",
       "c3           0.0086108 0.00600355 1.43428\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2i = fit(lmm(lrt ~ 1 + c1 + c2 + c3 + (1 + c1 + c2 + c3 | subj),kwdyz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " PDLCholF(Cholesky{Float64} with factor:\n",
       "4x4 Triangular{Float64,Array{Float64,2},:L,false}:\n",
       "  0.750618    0.0         0.0        0.0\n",
       "  0.144542    0.266359    0.0        0.0\n",
       " -0.0345324  -0.00627849  0.138568   0.0\n",
       " -0.0391828  -0.116144    0.0430527  0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2i.Î»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       "Formula: prt ~ 1 + c1 + c2 + c3 + ((1 + c1 + c2 + c3) | subj)\n",
       "\n",
       " logLik: -40364.956363, deviance: 80729.912726\n",
       "\n",
       " Variance components:\n",
       "                Variance    Std.Dev.  Corr.\n",
       " subj           0.573057    0.757006\n",
       "                0.096789    0.311109   0.53\n",
       "                0.020716    0.143931  -0.19 -0.19\n",
       "                0.016826    0.129714  -0.28 -0.28 -0.28\n",
       " Residual       0.957027    0.978277\n",
       " Number of obs: 28710; levels of grouping factors: 61\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "              Estimate Std.Error z value\n",
       "(Intercept)    12.4741 0.0972639 128.251\n",
       "c1            0.463096 0.0443697 10.4372\n",
       "c2            0.192511 0.0317935 6.05505\n",
       "c3           0.0423165 0.0307731 1.37511\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2j = fit(lmm(prt ~ 1 + c1 + c2 + c3 + (1 + c1 + c2 + c3 | subj),kwdyz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " PDLCholF(Cholesky{Float64} with factor:\n",
       "4x4 Triangular{Float64,Array{Float64,2},:L,false}:\n",
       "  0.773815    0.0        0.0        0.0\n",
       "  0.169872    0.268846   0.0        0.0\n",
       " -0.028671    0.0031853  0.144271   0.0\n",
       " -0.0374287  -0.117442   0.0488643  0.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2j.Î»"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.6",
   "language": "julia",
   "name": "julia 0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
