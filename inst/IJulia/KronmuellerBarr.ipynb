{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RePsychLing Kronmüller and Barr (2007)\n",
    "\n",
    "We apply the iterative reduction of LMM complexity to truncated response times of a 2x2x2 factorial psycholinguistic experiment (Kronmüller and Barr, 2007, Exp. 2; reanalyzed with an LMM in Barr, Levy, Scheepers and Tily, 2013). The data are from 56 subjects who responded to 32 items. Specifically, subjects had to select one of several objects presented on a monitor with a cursor. The manipulations involved (1) auditory instructions that maintained or broke a precedent of reference for the objects established over prior trials, (2) with the instruction being presented by the speaker who established the precedent (i.e., an old speaker) or a new speaker, and (3) whether the task had to be performed without or with a cognitive load consisting of six random digits. All factors were varied within subjects and within items. There were main effects of Load, Speaker, and Precedent; none of the interactions were significant. Although standard errors of fixed-effect coefficents varied slightly across models, our reanalyses afforded the same statistical inference about the experimental manipulations as the original article, irrespective of LMM specification. The purpose of the analysis is to illustrate an assessment of model complexity as far as variance components and correlation parameters are concerned, neither of which were in the focus of the original publication. \n",
    "\n",
    "## Data\n",
    "\n",
    "The data are available as `kb07` in the [RePsychLing package](https://github.com/dmbates/RePsychLing) for [R](http://www.r-project.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><tr><th></th><th>subj</th><th>item</th><th>RTtrunc</th><th>S</th><th>P</th><th>C</th><th>SP</th><th>SC</th><th>PC</th><th>SPC</th></tr><tr><th>1</th><td>30</td><td>1</td><td>2267.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>2</th><td>30</td><td>2</td><td>3856.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>3</th><td>30</td><td>3</td><td>1567.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>4</th><td>30</td><td>4</td><td>1732.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>5</th><td>30</td><td>5</td><td>2660.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>6</th><td>30</td><td>6</td><td>2763.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>7</th><td>30</td><td>7</td><td>3528.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>8</th><td>30</td><td>8</td><td>1741.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>9</th><td>30</td><td>9</td><td>3692.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>10</th><td>30</td><td>10</td><td>1949.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>11</th><td>30</td><td>11</td><td>2189.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>12</th><td>30</td><td>12</td><td>2207.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>13</th><td>30</td><td>13</td><td>2078.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>14</th><td>30</td><td>14</td><td>1901.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>15</th><td>30</td><td>15</td><td>4015.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>16</th><td>30</td><td>16</td><td>1880.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>17</th><td>30</td><td>17</td><td>1444.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>18</th><td>30</td><td>18</td><td>1683.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>19</th><td>30</td><td>19</td><td>2037.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>20</th><td>30</td><td>20</td><td>1168.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>21</th><td>30</td><td>21</td><td>1930.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>22</th><td>30</td><td>22</td><td>1843.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>23</th><td>30</td><td>23</td><td>4969.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>24</th><td>30</td><td>24</td><td>1798.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>25</th><td>30</td><td>25</td><td>2436.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>26</th><td>30</td><td>26</td><td>2018.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>27</th><td>30</td><td>27</td><td>2278.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>28</th><td>30</td><td>28</td><td>1866.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td></tr><tr><th>29</th><td>30</td><td>29</td><td>1743.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td></tr><tr><th>30</th><td>30</td><td>30</td><td>1963.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>-1.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></table>"
      ],
      "text/plain": [
       "1790x10 DataFrame\n",
       "| Row  | subj  | item | RTtrunc | S    | P    | C    | SP   | SC   | PC   |\n",
       "|------|-------|------|---------|------|------|------|------|------|------|\n",
       "| 1    | \"30\"  | \"1\"  | 2267.0  | 1.0  | -1.0 | 1.0  | -1.0 | 1.0  | -1.0 |\n",
       "| 2    | \"30\"  | \"2\"  | 3856.0  | -1.0 | 1.0  | -1.0 | -1.0 | 1.0  | -1.0 |\n",
       "| 3    | \"30\"  | \"3\"  | 1567.0  | -1.0 | -1.0 | -1.0 | 1.0  | 1.0  | 1.0  |\n",
       "| 4    | \"30\"  | \"4\"  | 1732.0  | 1.0  | 1.0  | -1.0 | 1.0  | -1.0 | -1.0 |\n",
       "| 5    | \"30\"  | \"5\"  | 2660.0  | 1.0  | -1.0 | -1.0 | -1.0 | -1.0 | 1.0  |\n",
       "| 6    | \"30\"  | \"6\"  | 2763.0  | -1.0 | 1.0  | 1.0  | -1.0 | -1.0 | 1.0  |\n",
       "| 7    | \"30\"  | \"7\"  | 3528.0  | -1.0 | -1.0 | 1.0  | 1.0  | -1.0 | -1.0 |\n",
       "| 8    | \"30\"  | \"8\"  | 1741.0  | 1.0  | 1.0  | 1.0  | 1.0  | 1.0  | 1.0  |\n",
       "| 9    | \"30\"  | \"9\"  | 3692.0  | 1.0  | -1.0 | 1.0  | -1.0 | 1.0  | -1.0 |\n",
       "| 10   | \"30\"  | \"10\" | 1949.0  | -1.0 | 1.0  | -1.0 | -1.0 | 1.0  | -1.0 |\n",
       "| 11   | \"30\"  | \"11\" | 2189.0  | -1.0 | -1.0 | -1.0 | 1.0  | 1.0  | 1.0  |\n",
       "⋮\n",
       "| 1779 | \"103\" | \"21\" | 1309.0  | 1.0  | 1.0  | -1.0 | 1.0  | -1.0 | -1.0 |\n",
       "| 1780 | \"103\" | \"22\" | 1623.0  | 1.0  | -1.0 | -1.0 | -1.0 | -1.0 | 1.0  |\n",
       "| 1781 | \"103\" | \"23\" | 2706.0  | -1.0 | 1.0  | 1.0  | -1.0 | -1.0 | 1.0  |\n",
       "| 1782 | \"103\" | \"24\" | 4281.0  | -1.0 | -1.0 | 1.0  | 1.0  | -1.0 | -1.0 |\n",
       "| 1783 | \"103\" | \"25\" | 2075.0  | 1.0  | 1.0  | 1.0  | 1.0  | 1.0  | 1.0  |\n",
       "| 1784 | \"103\" | \"26\" | 3179.0  | 1.0  | -1.0 | 1.0  | -1.0 | 1.0  | -1.0 |\n",
       "| 1785 | \"103\" | \"27\" | 1216.0  | -1.0 | 1.0  | -1.0 | -1.0 | 1.0  | -1.0 |\n",
       "| 1786 | \"103\" | \"28\" | 2286.0  | -1.0 | -1.0 | -1.0 | 1.0  | 1.0  | 1.0  |\n",
       "| 1787 | \"103\" | \"29\" | 1202.0  | 1.0  | 1.0  | -1.0 | 1.0  | -1.0 | -1.0 |\n",
       "| 1788 | \"103\" | \"30\" | 1581.0  | 1.0  | -1.0 | -1.0 | -1.0 | -1.0 | 1.0  |\n",
       "| 1789 | \"103\" | \"31\" | 1601.0  | -1.0 | 1.0  | 1.0  | -1.0 | -1.0 | 1.0  |\n",
       "| 1790 | \"103\" | \"32\" | 1941.0  | -1.0 | -1.0 | 1.0  | 1.0  | -1.0 | -1.0 |\n",
       "\n",
       "| Row  | SPC  |\n",
       "|------|------|\n",
       "| 1    | -1.0 |\n",
       "| 2    | 1.0  |\n",
       "| 3    | -1.0 |\n",
       "| 4    | -1.0 |\n",
       "| 5    | 1.0  |\n",
       "| 6    | -1.0 |\n",
       "| 7    | 1.0  |\n",
       "| 8    | 1.0  |\n",
       "| 9    | -1.0 |\n",
       "| 10   | 1.0  |\n",
       "| 11   | -1.0 |\n",
       "⋮\n",
       "| 1779 | -1.0 |\n",
       "| 1780 | 1.0  |\n",
       "| 1781 | -1.0 |\n",
       "| 1782 | 1.0  |\n",
       "| 1783 | 1.0  |\n",
       "| 1784 | -1.0 |\n",
       "| 1785 | 1.0  |\n",
       "| 1786 | -1.0 |\n",
       "| 1787 | -1.0 |\n",
       "| 1788 | 1.0  |\n",
       "| 1789 | -1.0 |\n",
       "| 1790 | 1.0  |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames,RCall,MixedModels\n",
    "kb07 = DataFrame(\"RePsychLing::kb07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximal linear mixed model (_maxLMM_)\n",
    "\n",
    "Barr et al. (2012, supplement) analyzed Kronmüller and Barr (2007, Exp. 2) with the _maxLMM_ comprising 16 variance component parameters (eight each for the random factors `subj` and `item`, respectively). This model takes a relatively long time to fit using `lmm` because there are so many parameters and the likelihood surface is very flat. To save time we start the optimization near the optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28586.317619598813"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0 = lmm(RTtrunc ~ 1+S+P+C+SP+SC+PC+SPC +\n",
    "(1+S+P+C+SP+SC+PC+SPC|subj) + (1+S+P+C+SP+SC+PC+SPC|item), kb07);\n",
    "\n",
    "MixedModels.objective!(m0,\n",
    "[0.4765945402846765,-0.049465200650367254,-0.05577395841877958,\n",
    "    0.029513337949340943,0.029148407625182948,0.03194864344405289,\n",
    "    -0.013919372830411688,-0.04638735990276547,0.10257407134683175,\n",
    "    -0.0171000112983217,-0.016603717040510488,-0.1109210610843561,\n",
    "    -0.02435319160421018,0.0126607985319349,0.021792305804416535,\n",
    "    0.10232424394072726,0.07801670286928138,-0.09440572778256788,\n",
    "    0.005078526659066913,-0.0134017916950307,-0.06505508009231055,\n",
    "    0.10841211573450886,0.0054641402665540385,-0.05402178547126058,\n",
    "    -0.1343169035616224,0.05153142117691683,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,\n",
    "    0.5699800437077661,-0.02339206691982298,-0.26704717626433516,\n",
    "    0.01736408969190548,0.029034597610324384,0.01783789093485394,\n",
    "    0.00848310344219369,0.004879390800290307,0.06399876167032546,\n",
    "    -0.288060036040779,0.003544393801046275,-0.030843446553322655,\n",
    "    0.004685779731614644,-0.023824295073761197,-0.05397308647226873,\n",
    "    0.042916034668339306,-0.01217658229652332,-0.01712436845429653,\n",
    "    -0.01634632724087294,0.10045183250207336,-0.008212424968067053,\n",
    "    0.08316744039186683,-0.006491337942497235,0.02291032480523459,\n",
    "    -0.0007845845820843916,-0.07761538290870172,0.021897215394384946,\n",
    "    -0.054052700984661306,-0.03210211651923669,0.05507672149152027,\n",
    "    0.,0.,0.,0.,0.,0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       "Formula: RTtrunc ~ 1 + S + P + C + SP + SC + PC + SPC + ((1 + S + P + C + SP + SC + PC + SPC) | subj) + ((1 + S + P + C + SP + SC + PC + SPC) | item)\n",
       "\n",
       " logLik: -14293.158809, deviance: 28586.317618\n",
       "\n",
       " Variance components:\n",
       "                Variance    Std.Dev.  Corr.\n",
       " subj         90768.454631  301.278035\n",
       "              5182.222981   71.987659  -0.43\n",
       "              5543.917579   74.457488  -0.47 -0.47\n",
       "              7587.207623   87.104579   0.21  0.21  0.21\n",
       "              8829.508465   93.965464   0.20  0.20  0.20  0.20\n",
       "              1821.402959   42.677898   0.47  0.47  0.47  0.47  0.47\n",
       "              7422.585309   86.154427  -0.10 -0.10 -0.10 -0.10 -0.10 -0.10\n",
       "              3802.035391   61.660647  -0.48 -0.48 -0.48 -0.48 -0.48 -0.48 -0.48\n",
       " item         129824.964990  360.312316\n",
       "              1855.413006   43.074505  -0.34\n",
       "              62393.466734  249.786843  -0.68 -0.68\n",
       "              2948.599566   54.301009   0.20  0.20  0.20\n",
       "              1042.766057   32.291888   0.57  0.57  0.57  0.57\n",
       "              1620.037731   40.249692   0.28  0.28  0.28  0.28  0.28\n",
       "              4700.066245   68.557029   0.08  0.08  0.08  0.08  0.08  0.08\n",
       "              4820.371798   69.428897   0.04  0.04  0.04  0.04  0.04  0.04  0.04\n",
       " Residual     399612.449739  632.149072\n",
       " Number of obs: 1790; levels of grouping factors: 56, 32\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error  z value\n",
       "(Intercept)   2180.63   76.8191  28.3865\n",
       "S            -66.9899   19.3339 -3.46489\n",
       "P            -333.881   47.6663 -7.00456\n",
       "C              78.987   21.2346  3.71973\n",
       "SP            22.1518   20.3356  1.08931\n",
       "SC           -18.9244   17.5052 -1.08108\n",
       "PC            5.26196    22.421 0.234688\n",
       "SPC           -23.951   21.0193 -1.13948\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fit converges and produces what look like reasonable parameter estimates (i.e., no variance components with estimates close to zero; no correlation parameters with values close to $\\pm1$).\n",
    "\n",
    "Further investigation, however, shows that the Cholesky factors of the covariance matrices of the unconditional distribution of the within-subject and within-item random effects are singular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       " PDLCholF(Cholesky{Float64} with factor:\n",
       "8x8 Triangular{Float64,Array{Float64,2},:L,false}:\n",
       "  0.476593    0.0         0.0          0.0         0.0  0.0  0.0  0.0\n",
       " -0.0494647   0.102574    0.0          0.0         0.0  0.0  0.0  0.0\n",
       " -0.055773   -0.0170985   0.102324     0.0         0.0  0.0  0.0  0.0\n",
       "  0.0295124  -0.0166024   0.0780166    0.108412    0.0  0.0  0.0  0.0\n",
       "  0.029148   -0.110922   -0.0944035    0.00546411  0.0  0.0  0.0  0.0\n",
       "  0.0319486  -0.0243532   0.00507938  -0.0540216   0.0  0.0  0.0  0.0\n",
       " -0.0139184   0.0126607  -0.0134017   -0.134316    0.0  0.0  0.0  0.0\n",
       " -0.0463876   0.0217912  -0.0650552    0.0515311   0.0  0.0  0.0  0.0)\n",
       " PDLCholF(Cholesky{Float64} with factor:\n",
       "8x8 Triangular{Float64,Array{Float64,2},:L,false}:\n",
       "  0.56998      0.0          0.0         …   0.0        0.0  0.0  0.0\n",
       " -0.0233922    0.0639987    0.0             0.0        0.0  0.0  0.0\n",
       " -0.267047    -0.288061     0.04291         0.0        0.0  0.0  0.0\n",
       "  0.017364     0.00353845  -0.0122178       0.0        0.0  0.0  0.0\n",
       "  0.0290349   -0.0308473   -0.0171533       0.0218693  0.0  0.0  0.0\n",
       "  0.0178373    0.00469399  -0.0162761   …  -0.0540658  0.0  0.0  0.0\n",
       "  0.00848297  -0.0238197    0.100497       -0.0319698  0.0  0.0  0.0\n",
       "  0.00487949  -0.0539799   -0.00825907      0.0550279  0.0  0.0  0.0)        "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0.λ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the random effects vectors for `subj` and for `item` are 8-dimensional there are 4 directions with no variability in the `subj` random effects and 3 directions with no variability in the `item` random effects.\n",
    "\n",
    "### Evaluation of singular value decomposition (svd) for _maxLMM_\n",
    "\n",
    "Considering that there are only 56 subjects and 32 items it is quite optimistic to expect to estimate 36 highly nonlinear covariance parameters for `subj` and another 36 for `item`.\n",
    "\n",
    "The singular value decompositions of these factors are equivalent to a _principal components analysis_ (PCA) of the covariance matrices.  The variance components are the squares of the singular values and the component loadings are the left singular vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       " [0.238286,0.0395663,0.0305344,0.0193237,0.0,0.0,0.0,0.0]       \n",
       " [0.415843,0.0768207,0.0170854,0.0109844,0.00278772,0.0,0.0,0.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svds = map(svdfact,m0.λ);\n",
    "varcomp = [x[:S].^2 for x in svds]  # variances of the principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       " [0.727124,0.120736,0.0931747,0.0589659,0.0,0.0,0.0,0.0]       \n",
       " [0.794319,0.146738,0.0326356,0.0209818,0.00532495,0.0,0.0,0.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(x->x ./sum(x), varcomp)   # proportion of variance in each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       " [0.727124,0.847859,0.941034,1.0,1.0,1.0,1.0,1.0]     \n",
       " [0.794319,0.941058,0.973693,0.994675,1.0,1.0,1.0,1.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(x->cumsum(x ./ sum(x)), varcomp)  # cumulative proportions of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       " 8x8 Array{Float64,2}:\n",
       " -0.975171   -0.0236937   0.110507   …  -0.0232548  -0.0720005   0.0697229\n",
       "  0.110936   -0.062438    0.360765      -0.0300218   0.168765    0.706214 \n",
       "  0.115533   -0.285156    0.261866      -0.220285   -0.205188    0.387967 \n",
       " -0.0608491  -0.657069   -0.116164       0.655537    0.243853    0.0897252\n",
       " -0.0730182   0.322259   -0.722651       0.0587394  -0.0391085   0.566407 \n",
       " -0.0669295   0.217408    0.0950017  …  -0.154439    0.912439   -0.0141082\n",
       "  0.0307724   0.574871    0.394548       0.671865   -0.124433    0.0563242\n",
       "  0.0944791  -0.0298937  -0.297743       0.203958    0.123327   -0.116805         \n",
       " 8x8 Array{Float64,2}:\n",
       " -0.860721      0.466888   -0.0502723  …   0.0662198   0.0281145  -0.178243\n",
       "  0.0130449    -0.239939    0.0141917      0.659885    0.579556   -0.390245\n",
       "  0.505933      0.800512   -0.136057       0.100172    0.0823936  -0.229744\n",
       " -0.0288903    -0.0273149  -0.462091       0.325901   -0.158737    0.310215\n",
       " -0.0339228     0.124925    0.1638        -0.332674    0.759176    0.464003\n",
       " -0.0298787    -0.0252692  -0.323191   …   0.328461    0.044028    0.42244 \n",
       "  0.000963501   0.144411   -0.381106       0.032188    0.0640498   0.317542\n",
       "  0.0118693     0.213963    0.699076       0.473631   -0.221244    0.415133"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[:U] for x in svds]   # component loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-correlation-parameter linear mixed model (_zcpLMM_)\n",
    "\n",
    "As a first step of model reduction, we propose to start with a model including all 16 variance components, but no correlation parameters. Note that here we go through the motion to be consistent with the recommended strategy. The large number of components with zero or close to zero variance in _maxLMM_ already strongly suggests the need for a reduction of the number of variance components--as done in the next step. For this _zcpLMM_, we extract the vector-valued variables from the model matrix without the intercept column which is provided by the R formula. Then, we use the new double-bar syntax for `lmer()` to force correlation parameters to zero.\n",
    "\n",
    "At present the `lmm` formulas for these models are rather tedious to write "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       "Formula: RTtrunc ~ 1 + S + P + C + SP + SC + PC + SPC + (1 | subj) + ((0 + S) | subj) + ((0 + P) | subj) + ((0 + C) | subj) + ((0 + SP) | subj) + ((0 + SC) | subj) + ((0 + PC) | subj) + ((0 + SPC) | subj) + (1 | item) + ((0 + S) | item) + ((0 + P) | item) + ((0 + C) | item) + ((0 + SP) | item) + ((0 + SC) | item) + ((0 + PC) | item) + ((0 + SPC) | item)\n",
       "\n",
       " logLik: -14341.033697, deviance: 28682.067394\n",
       "\n",
       " Variance components:\n",
       "                Variance    Std.Dev.  Corr.\n",
       " subj         90911.807064  301.515849\n",
       "                0.000000    0.000000   0.00\n",
       "                0.000000    0.000000   0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00  0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00  0.00  0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00  0.00  0.00  0.00  0.00\n",
       " item         132591.476856  364.131126\n",
       "                0.000000    0.000000   0.00\n",
       "              62510.385022  250.020769   0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00  0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00  0.00  0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00  0.00  0.00  0.00  0.00\n",
       " Residual     458473.619575  677.106801\n",
       " Number of obs: 1790; levels of grouping factors: 56, 32\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error  z value\n",
       "(Intercept)   2180.54   77.6084  28.0967\n",
       "S            -67.0974   16.0047 -4.19237\n",
       "P            -333.774   47.0064 -7.10061\n",
       "C             79.0781   16.0047  4.94094\n",
       "SP            22.2429   16.0047  1.38977\n",
       "SC           -18.8168   16.0047 -1.17571\n",
       "PC             5.1544   16.0047 0.322056\n",
       "SPC          -24.0421   16.0047 -1.50219\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = fit(lmm(RTtrunc ~ 1+S+P+C+SP+SC+PC+SPC +\n",
    "(1|subj)+(0+S|subj)+(0+P|subj)+(0+C|subj)+\n",
    "(0+SP|subj)+(0+SC|subj)+(0+PC|subj)+(0+SPC|subj) +\n",
    "(1|item)+(0+S|item)+(0+P|item)+(0+C|item)+\n",
    "(0+SP|item)+(0+SC|item)+(0+PC|item)+(0+SPC|item), kb07))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods in `lmm` do not fit such models well.  The `lmer` function in the [lme4 package](https://github.com/lme4/lme4) for [R](http://www.r-project.org) is more successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28670.913319613523"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MixedModels.objective!(m1,[0.461098922494114, 0.0477069109747168, 0.0700075426143427, \n",
    "    0.0948946258676561, 0.113579418439824, 0, 0.0987708829960627,\n",
    "    0, 0.553747500257642, 0, 0.380220894182068, \n",
    "    0.0805837316205983, 0, 0.0413129898395064, \n",
    "    0.0900636564806011, 0.075488529192162])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       "Formula: RTtrunc ~ 1 + S + P + C + SP + SC + PC + SPC + (1 | subj) + ((0 + S) | subj) + ((0 + P) | subj) + ((0 + C) | subj) + ((0 + SP) | subj) + ((0 + SC) | subj) + ((0 + PC) | subj) + ((0 + SPC) | subj) + (1 | item) + ((0 + S) | item) + ((0 + P) | item) + ((0 + C) | item) + ((0 + SP) | item) + ((0 + SC) | item) + ((0 + PC) | item) + ((0 + SPC) | item)\n",
       "\n",
       " logLik: -14335.456660, deviance: 28670.913320\n",
       "\n",
       " Variance components:\n",
       "                Variance    Std.Dev.  Corr.\n",
       " subj         91738.707471  302.883984\n",
       "              982.040875   31.337531   0.00\n",
       "              2114.728844   45.986181   0.00  0.00\n",
       "              3885.506056   62.333828   0.00  0.00  0.00\n",
       "              5566.265760   74.607411   0.00  0.00  0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00  0.00  0.00\n",
       "              4209.413273   64.879991   0.00  0.00  0.00  0.00  0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00  0.00  0.00  0.00  0.00\n",
       " item         132308.540859  363.742410\n",
       "                0.000000    0.000000   0.00\n",
       "              62378.660697  249.757203   0.00  0.00\n",
       "              2801.941413   52.933368   0.00  0.00  0.00\n",
       "                0.000000    0.000000   0.00  0.00  0.00  0.00\n",
       "              736.437033   27.137373   0.00  0.00  0.00  0.00  0.00\n",
       "              3499.955476   59.160422   0.00  0.00  0.00  0.00  0.00  0.00\n",
       "              2458.818311   49.586473   0.00  0.00  0.00  0.00  0.00  0.00  0.00\n",
       " Residual     431483.649146  656.874150\n",
       " Number of obs: 1790; levels of grouping factors: 56, 32\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error  z value\n",
       "(Intercept)   2180.61   77.5494   28.119\n",
       "S            -67.0412   16.0817  -4.1688\n",
       "P             -333.83   47.2036 -7.07213\n",
       "C             79.0015   19.9506  3.95985\n",
       "SP            22.1663   18.4521  1.20129\n",
       "SC           -18.8731   16.2511 -1.16134\n",
       "PC            5.21061   20.6307 0.252566\n",
       "SPC          -23.9655   17.8304 -1.34409\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.fit = false; fit(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance components that are estimated as 0. can be dropped without affecting the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28670.913319613494"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = lmm(RTtrunc ~ 1+S+P+C+SP+SC+PC+SPC +\n",
    "    (1|subj)+(0+S|subj)+(0+P|subj)+(0+C|subj)+(0+SP|subj)+(0+PC|subj) +\n",
    "    (1|item)+(0+P|item)+(0+C|item)+(0+SC|item)+(0+PC|item)+(0+SPC|item), kb07);\n",
    "MixedModels.objective!(m2,MixedModels.θ(m1)[[1:5,7,9,11,12,14:16]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look further for trivial variance components, we examine the proportion of the \n",
    "variance of the random effects for `subj` and for `item`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       " [0.845544,0.896848,0.935645,0.971457,0.990949,1.0]\n",
       " [0.647986,0.953487,0.970629,0.984351,0.996393,1.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cumulativevar{T<:Real}(svds::Vector{T})\n",
    "    var = cumsum([abs2(x) for x in svds])  # cumulative variances\n",
    "    var ./ var[end]  # cumulative proportion\n",
    "end\n",
    "cumulativevar(m::LinearMixedModel) = map(cumulativevar,map(svdvals, m.λ))\n",
    "\n",
    "cumulativevar(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `subj` 85% of the variability in the unconditional distribution of the random effects is attributed to the random intercept.  For `item` 95% of the variability in the unconditional distribution is attributed to the random intercept and the random effect for `P`.\n",
    "\n",
    "At this point we could reduce to these random effects and reintroduce the correlation between the random effects for `item`.\n",
    "\n",
    "For some reason this fit, even starting from the converged `lmer` values, does not produce the same deviance.  In the [lme4 package](https://github.com/lme4/lme4) `m0` is not a significantly better fit than this model.  Here, it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_1: 28689.95953, [0.537365,-0.258992,0.26859,0.440834]\n",
      "f_2: 29076.1246, [0.095609,-0.153327,0.0,0.0]\n",
      "f_3: 28741.4515, [0.425541,-0.246119,0.0930285,0.254338]\n",
      "f_4: 28690.45069, [0.523578,-0.257675,0.244015,0.414138]\n",
      "f_5: 28689.94941, [0.535863,-0.258852,0.265861,0.437858]\n",
      "f_6: 28689.96377, [0.526882,-0.255787,0.26638,0.432938]\n",
      "f_7: 28689.94822, [0.534093,-0.258254,0.265962,0.436895]\n",
      "f_8: 28689.99481, [0.529312,-0.247708,0.265213,0.445168]\n",
      "f_9: 28689.94806, [0.533612,-0.257182,0.265887,0.437733]\n",
      "f_10: 28689.94795, [0.533297,-0.257448,0.265893,0.437076]\n",
      "f_11: 28689.94793, [0.53333,-0.25736,0.26589,0.437236]\n",
      "f_12: 28689.94794, [0.533203,-0.257084,0.265886,0.437292]\n",
      "f_13: 28689.94793, [0.533312,-0.257321,0.26589,0.437244]\n",
      "f_14: 28689.94796, [0.53302,-0.257416,0.265886,0.43729]\n",
      "f_15: 28689.94793, [0.533283,-0.257331,0.265889,0.437248]\n",
      "f_16: 28689.94793, [0.5333,-0.257325,0.26589,0.437246]\n",
      "f_17: 28689.94793, [0.53327,-0.257306,0.265887,0.43726]\n",
      "f_18: 28689.94793, [0.533294,-0.257321,0.265889,0.437249]\n",
      "FTOL_REACHED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       "Formula: RTtrunc ~ 1 + S + P + SP + SC + PC + SPC + ((1 + P) | item) + (1 | subj)\n",
       "\n",
       " logLik: -14344.973964, deviance: 28689.947928\n",
       "\n",
       " Variance components:\n",
       "                Variance    Std.Dev.  Corr.\n",
       " item         132302.682783  363.734357\n",
       "              63690.445101  252.369660  -0.70\n",
       " subj         88939.184156  298.226733\n",
       " Residual     465196.049819  682.052820\n",
       " Number of obs: 1790; levels of grouping factors: 32, 56\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "             Estimate Std.Error  z value\n",
       "(Intercept)   2180.66    77.347  28.1932\n",
       "S             -67.107   16.1215 -4.16256\n",
       "P            -333.764   47.4366 -7.03601\n",
       "SP            22.1176   16.1215  1.37193\n",
       "SC           -18.8073   16.1215  -1.1666\n",
       "PC            5.14488   16.1215 0.319131\n",
       "SPC          -23.9168   16.1215 -1.48353\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = lmm(RTtrunc ~ 1+S+P+SP+SC+PC+SPC + (1+P|item) + (1|subj), kb07);\n",
    "MixedModels.objective!(m3,\n",
    "[0.537364783211338, -0.258992402219962, 0.268590222400181,0.440834222302868])\n",
    "fit(m3,true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><tr><th></th><th>Df</th><th>Deviance</th><th>Chisq</th><th>pval</th></tr><tr><th>1</th><td>12</td><td>28689.9479284958</td><td>NaN</td><td>NaN</td></tr><tr><th>2</th><td>81</td><td>28586.317617892324</td><td>103.63031060347566</td><td>0.00443240818953816</td></tr></table>"
      ],
      "text/plain": [
       "2x4 DataFrame\n",
       "| Row | Df | Deviance | Chisq  | pval       |\n",
       "|-----|----|----------|--------|------------|\n",
       "| 1   | 12 | 28689.9  | NaN    | NaN        |\n",
       "| 2   | 81 | 28586.3  | 103.63 | 0.00443241 |"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MixedModels.lrt(m3,m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       " PDLCholF(Cholesky{Float64} with factor:\n",
       "2x2 Triangular{Float64,Array{Float64,2},:L,false}:\n",
       "  0.533294  0.0     \n",
       " -0.257321  0.265889)\n",
       " PDScalF(0.43724873481629667,1)                                                                                                       "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.λ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.6",
   "language": "julia",
   "name": "julia 0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
